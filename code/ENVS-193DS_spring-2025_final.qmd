---
title: "ENVS-193DS_spring-2025_final"
author: Matthew Roco-Calvo
date: 06/11/2025
format:
  html:
    toc: true # use this to display a table of contents
execute:
  message: false # use this to make sure messages don't show up
  warning: false # use this to make sure warnings don't show up
---

## Packages and Data

```{r}

library(tidyverse) 
library(janitor)
library(here)
library(gt)
library(flextable)
library(readxl)

sst <- read.csv(here("data", "SST_update2023.csv")) # creating a dataframe "sst" for question 2 using SBC LTER dataset on sea surface temperatures.

nest_boxes <- read.csv(here("data", "occdist.csv")) #creating a dataframe "nest_boxes" for question 3 using the data provided from the study

```


## Question 1:Research writing

### A: Transparent statistical methods

In part 1 of their results section, they made use of a Pearson’s r test, while in part 2 they used a one way Analysis of Variance (ANOVA).

### B: More information needed

For part 2 of their results, the authors could run a Tukey’s Honestly Significant Difference test (Tukey’s HSD), as their ANOVA only reveals that there is a significant difference between average nitrogen loads (kg/year) in at at least two of the groups, which could be any pairing. A Tukey’s HSD test would reveal which groups’ average nitrogen are significantly different, providing more context in terms of what sources influence nitrogen runoff/pollution the most. Additionally, they could calculate the Eta squared, which is the effect size for an ANOVA. This would help to provide more context, as it would allow readers to understand how strong the effect of source is on average nitrogen loads.

### C: Suggestions for rewriting

We found that there is a correlation between distance from headwater (km) and annual total nitrogen load (kg/year), (Pearson’s r test, r = value of correlation, R^2 = coefficient of determination, p = 0.03)

Additionally, we determined that there is a large difference ( n = Eta squared) between nitrogen pollution sources (urban land, atmospheric deposition, fertilizer, wastewater treatment, and grasslands) in average nitrogen load in kg/year (one-way ANOVA, f(degrees of freedom within groups, degrees of freedom between groups) = f-statistic,  p = 0.02, alpha = significance level).

## Question 2: Data visualization

### A: Cleaning and summarizing

```{r}

sst_clean <- sst |> #creating a new dataframe sst_clean from sst dataframe read above.
  mutate(year = year(date)) |>  #creating a new column "year" with only the year from the existing date column
  mutate(month = month(date)) |>  #creating a new column "month" with only the year from the existing date column
  select(temp, year, month) |> #selecting to only include year, month, and temperature column
  mutate(month = as_factor(month)) |>  #making the months a factor
  mutate(year = as_factor(year)) |>   #making the year a factor 
  group_by(month, year) |> 
  summarize(
    mean_monthly_sst = mean(temp, na.rm = TRUE) #creating a new column to summarize the mean monthly SST
  ) |> 
  ungroup() |>  #ungrouping data
  filter(year %in% c(2018, #filtering to only include years 2018-2019
                     2019,
                     2020,
                     2021,
                     2022,
                     2023 ))
    
```

### B: Visualize the data

```{r}

ggplot(data = sst_clean, #starting with the sst_clean dataframe created in problem 2a
       aes(x = month, #x axis in month
           y = mean_monthly_sst, #y axis in mean monthly sea surface temperature
           color = year, #coloring and grouping by year
           group = year)) +
  geom_line() + #adding the first layer which is a line chart
  geom_point() +#adding the second layer which is a scatter plot
  scale_x_discrete( #relabelling the Months from numbers to text
    label = c( 
      "1" = "Jan",
      "2" = "Feb",
      "3" = "Mar",
      "4" = "Apr",
      "5" = "May",
      "6" = "Jun",
      "7" = "Jul",
      "8" = "Aug",
      "9" = "Sep",
      "10" = "Oct",
      "11" = "Nov",
      "12" = "Dec"
    )
  ) +
  
  
  labs( x = "Month", #labeling the x axis "Month"
        y = "Mean Monthly Sea Surface Temperature (C)", #labeling the y axis as mean monthly sea surface temp
        color = "Year" #labeling the axis as year
        ) +
  scale_color_manual(values = #adding a gradient of color manually. scale_color_gradient did not work with discrete data
                       c(
                         "2018" = "lightblue",
                         "2019" = "steelblue1",
                         "2019" = "steelblue2",
                         "2020" = "steelblue3",
                         "2021" = "steelblue",
                         "2022" = "steelblue4",
                        "2023" = "darkblue"
                       )) +
  theme(
    panel.grid = element_blank(), #removing gridlines 
    panel.background = element_blank(),#making background white
    panel.border = element_rect(color = "black", fill = NA, linewidth = 1), #adding a pannel border
    legend.position = c(0.10, 0.75) #moving legend to inside top left.
  )



```

## 3: Data analysis

### A: Response variable

The 1’s and 0’s in this data set indicate that the researchers observed a species of bird within the nest box. For example, a 1 could show they found a common sterling in one of their boxes, while 0’s for the other columns shows that the other species (swift parrot, tree martin) were not there.

### B: Purpose of study



### C: Difference in “seasons"

The two seasons being 2016 and 2019, are two years where boxes were observed. In 2016 the boxes were newly deployed, and 3 years later in 2019 in order to compare species usage between freshly deployed boxes and ones that have been established for some time. In both seasons, observations occurred in November/December, which was during key life cycles periods for all 3 species including nest building, nestling, and incubation



## 4: Affective and exploratory visualizations

## A: Comparing visualizations

In homework 3, I used jitterplots with added means to compare bike travel times between those going towards Campbell hall and those going towards home. In my affective visualization however, I chose to use lines representative of the distribution of histograms of the two groups to represent the data. In terms of similarities, both of them show the distribution of data points, such as what time ranges were more common, and where peaks occurred, modality, and others, although the distribution was more obvious in my affective visualization project. In terms of patterns between both visualizations, both displayed that the mean duration of the bike towards Campbell was shorter than the mean duration of the bike towards home. Additionally both visualizations showed bimodality in both directions, or having two peaks or clusters of data points. For example, the lines in the affective visualization had two peaks, while in the scatterplot data you could see two areas where times were grouped.

During week 9, I received feedback to flip the end point buildings horizontally (my apartment complex and Campbell hall) in order for them to be mirror images of each other. I incorporated this advice into my piece, which I think increased visual cohesion. Additionally, I was suggested to add elements of biking to the piece, which I did in the form of having two bikes traveling along the tops of the lines. Lastly, I received a suggestion to use the actual histogram (rather than a line showing the distribution) and place buildings in each of the bars. I attempted to do this, however many of the buildings and objects that I was attempting to highlight were shorter and wider, rather than the narrow and tall buildings which would be required to fill taller bars (with the exception of Stroke tower), and so I did not ultimately use this suggestion.
